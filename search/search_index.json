{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CHBH Computing on Bear This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages. Getting Started Contributing This page is a work-in-progress! Contributions from github PRs or by emailing Andrew...","title":"Home"},{"location":"#chbh-computing-on-bear","text":"This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages.","title":"CHBH Computing on Bear"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#contributing","text":"This page is a work-in-progress! Contributions from github PRs or by emailing Andrew...","title":"Contributing"},{"location":"bear/","text":"Getting started on BEAR This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages. Here we provide a set of links, tips and tricks for getting started. Mostly linking out to other places. Step 0: Linux Bear provide a Introduction to Linux guide. Many computing services on bear rely on linux. There are in-person workshops and an online canvas courses available on this page. Step 1: BlueBEAR Bear also provide a Introduction to BlueBEAR course. There are in person workshops and an online canvas course. Step 2: RDS Projects You'll need to be a member of a Bear project and have a Bear linux account to use BlueBEAR. Your PI and lab can help with this. A detailed guide for accessing BEAR is provided on the technical docs. Step 3: Bear Portal BEAR Portal provides web-based access to a range of BEAR services, such as JupyterLab, RStudio, and various other GUI applications. BEAR Portal is only available on campus or using the University Remote Access Service. Step 4: Launching interactive sessions From BEAR Portal there are three options for launching an interactive analysis session. Some software packages have GUI Apps installed on BlueBEAR that can be launched from the Bear Portal - the main example for neuroimaging analysis is Matlab. JupyterLab and RStudio are installed as standalone apps that can be launched from BEAR Portal. (ote that only packages installed on Bear Apps are available to load in JupyterLab). A complete Linux Desktop can be launched as the BlueBEAR GUI . BlueBEAR GUI is effectively a blank-slate linux desktop, into which you can load the modules for various applications, specify environment variables etc. by using the built-in Terminal client (see image below), and then ultimately launch the interface for the application that you require. Step 5: Running cluster jobs with Slurm There are two ways to submit a cluster job - the bluebear terminal or the Bear Portal https://docs.bear.bham.ac.uk/bluebear/jobs/ https://docs.bear.bham.ac.uk/portal/jobs/ Step 6: Neuroimaging analysis software on Bear The following software is available on BlueBEAR. Toolbox GUI App Bear Apps Modules Notes FSL N/A Bear Apps FSL Pip install modules via venv Python JupyterLab Bear Apps Python Bear Apps or pip/venv MNE-Python JupyterLab Bear Apps MNE Bear Apps or pip/venv Matlab MatLab Bear Apps MatLab Fieldtrip MatLab None Load within MatLab script EEGLab MatLab None Load within MatLab script SPM MatLab None Load within MatLab script R Rstudio Bear Apps R Freesurfer N/A Bear Apps Freesurfer","title":"Getting Started on Bear"},{"location":"bear/#getting-started-on-bear","text":"This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages. Here we provide a set of links, tips and tricks for getting started. Mostly linking out to other places.","title":"Getting started on BEAR"},{"location":"bear/#step-0-linux","text":"Bear provide a Introduction to Linux guide. Many computing services on bear rely on linux. There are in-person workshops and an online canvas courses available on this page.","title":"Step 0: Linux"},{"location":"bear/#step-1-bluebear","text":"Bear also provide a Introduction to BlueBEAR course. There are in person workshops and an online canvas course.","title":"Step 1: BlueBEAR"},{"location":"bear/#step-2-rds-projects","text":"You'll need to be a member of a Bear project and have a Bear linux account to use BlueBEAR. Your PI and lab can help with this. A detailed guide for accessing BEAR is provided on the technical docs.","title":"Step 2: RDS Projects"},{"location":"bear/#step-3-bear-portal","text":"BEAR Portal provides web-based access to a range of BEAR services, such as JupyterLab, RStudio, and various other GUI applications. BEAR Portal is only available on campus or using the University Remote Access Service.","title":"Step 3: Bear Portal"},{"location":"bear/#step-4-launching-interactive-sessions","text":"From BEAR Portal there are three options for launching an interactive analysis session. Some software packages have GUI Apps installed on BlueBEAR that can be launched from the Bear Portal - the main example for neuroimaging analysis is Matlab. JupyterLab and RStudio are installed as standalone apps that can be launched from BEAR Portal. (ote that only packages installed on Bear Apps are available to load in JupyterLab). A complete Linux Desktop can be launched as the BlueBEAR GUI . BlueBEAR GUI is effectively a blank-slate linux desktop, into which you can load the modules for various applications, specify environment variables etc. by using the built-in Terminal client (see image below), and then ultimately launch the interface for the application that you require.","title":"Step 4: Launching interactive sessions"},{"location":"bear/#step-5-running-cluster-jobs-with-slurm","text":"There are two ways to submit a cluster job - the bluebear terminal or the Bear Portal https://docs.bear.bham.ac.uk/bluebear/jobs/ https://docs.bear.bham.ac.uk/portal/jobs/","title":"Step 5: Running cluster jobs with Slurm"},{"location":"bear/#step-6-neuroimaging-analysis-software-on-bear","text":"The following software is available on BlueBEAR. Toolbox GUI App Bear Apps Modules Notes FSL N/A Bear Apps FSL Pip install modules via venv Python JupyterLab Bear Apps Python Bear Apps or pip/venv MNE-Python JupyterLab Bear Apps MNE Bear Apps or pip/venv Matlab MatLab Bear Apps MatLab Fieldtrip MatLab None Load within MatLab script EEGLab MatLab None Load within MatLab script SPM MatLab None Load within MatLab script R Rstudio Bear Apps R Freesurfer N/A Bear Apps Freesurfer","title":"Step 6: Neuroimaging analysis software on Bear"},{"location":"home/","text":"CHBH Computing on Bear This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages. Getting Started Contributing This page is a work-in-progress! Contributions from github PRs or by emailing Andrew...","title":"CHBH Computing on Bear"},{"location":"home/#chbh-computing-on-bear","text":"This page collects tutorials and examples for neuroimaging analyses to run on BlueBEAR. This is intended to extend the main Bear Technical Documentation pages.","title":"CHBH Computing on Bear"},{"location":"home/#getting-started","text":"","title":"Getting Started"},{"location":"home/#contributing","text":"This page is a work-in-progress! Contributions from github PRs or by emailing Andrew...","title":"Contributing"},{"location":"R/R/","text":"R for statistical computing The R project is a free software environment for statistical computing and graphics. R Versions Bear Apps has several versions of MNE-Python as loadable modules. R-Studio GUI App RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, and tools for plotting, history, debugging, and workspace management. You can open an interactive RStudio session through the Bear Portal. The pre-installed R versions can be loaded. Neuroimaging specific R packages Here is a list of R packages commonly used for neuroimaging analysis. FSLR Wrapper functions that interface with 'FSL' , a powerful and commonly-used 'neuroimaging' software, using system commands. R Example for BEAR knitr::opts_chunk$set(echo = TRUE) library(ggplot2) # Simulate some data time <- 0:99 set.seed(1) noise <- rnorm(100) disorder <- time * 4 + 100 + noise * 20 dis_df <- data.frame(time, disorder) # Create a plot ggplot(dis_df, aes(x = time, y = disorder)) + geom_point() + geom_smooth(method = \"lm\") # Fit model lm_fit <- lm(disorder ~ time, dis_df) summary(lm_fit)","title":"R"},{"location":"R/R/#r-for-statistical-computing","text":"The R project is a free software environment for statistical computing and graphics.","title":"R for statistical computing"},{"location":"R/R/#r-versions","text":"Bear Apps has several versions of MNE-Python as loadable modules.","title":"R Versions"},{"location":"R/R/#r-studio-gui-app","text":"RStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, and tools for plotting, history, debugging, and workspace management. You can open an interactive RStudio session through the Bear Portal. The pre-installed R versions can be loaded.","title":"R-Studio GUI App"},{"location":"R/R/#neuroimaging-specific-r-packages","text":"Here is a list of R packages commonly used for neuroimaging analysis.","title":"Neuroimaging specific R packages"},{"location":"R/R/#fslr","text":"Wrapper functions that interface with 'FSL' , a powerful and commonly-used 'neuroimaging' software, using system commands.","title":"FSLR"},{"location":"R/R/#r-example-for-bear","text":"knitr::opts_chunk$set(echo = TRUE) library(ggplot2) # Simulate some data time <- 0:99 set.seed(1) noise <- rnorm(100) disorder <- time * 4 + 100 + noise * 20 dis_df <- data.frame(time, disorder) # Create a plot ggplot(dis_df, aes(x = time, y = disorder)) + geom_point() + geom_smooth(method = \"lm\") # Fit model lm_fit <- lm(disorder ~ time, dis_df) summary(lm_fit)","title":"R Example for BEAR"},{"location":"fsl/fsl/","text":"FSL FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data. FSL Modules A range of installed FSL versions are available as modules on Bear Apps . Bear Portal GUI The following code snippet can be executed in a terminal from within the Bear Portal GUI. It will load a pre-installed FSL version into the terminal where is can be used as normal. module load FSL/6.0.5.1-foss-2021a-fslpython We can then use FSL command line functions as normal. fsl_anat --help Submitting FSL Jobs #!/bin/bash #SBATCH --ntasks 1 #SBATCH --time 30:0 #SBATCH --mem 50G #SBATCH --qos bbdefault #SBATCH --array=1-48 set -eu module purge; module load bluebear module load MATLAB/2019b # load the MATLAB version you need # apply matlab script to each index in the array (here, the MATLAB script is programmed such that the input ID is used as the subject ID) matlab -nodisplay -r \"run /rds/homes/d/dueckerk/startup.m, e1_fun_ICA(${SLURM_ARRAY_TASK_ID}), quit\"","title":"FSL"},{"location":"fsl/fsl/#fsl","text":"FSL is a comprehensive library of analysis tools for FMRI, MRI and DTI brain imaging data.","title":"FSL"},{"location":"fsl/fsl/#fsl-modules","text":"A range of installed FSL versions are available as modules on Bear Apps .","title":"FSL Modules"},{"location":"fsl/fsl/#bear-portal-gui","text":"The following code snippet can be executed in a terminal from within the Bear Portal GUI. It will load a pre-installed FSL version into the terminal where is can be used as normal. module load FSL/6.0.5.1-foss-2021a-fslpython We can then use FSL command line functions as normal. fsl_anat --help","title":"Bear Portal GUI"},{"location":"fsl/fsl/#submitting-fsl-jobs","text":"#!/bin/bash #SBATCH --ntasks 1 #SBATCH --time 30:0 #SBATCH --mem 50G #SBATCH --qos bbdefault #SBATCH --array=1-48 set -eu module purge; module load bluebear module load MATLAB/2019b # load the MATLAB version you need # apply matlab script to each index in the array (here, the MATLAB script is programmed such that the input ID is used as the subject ID) matlab -nodisplay -r \"run /rds/homes/d/dueckerk/startup.m, e1_fun_ICA(${SLURM_ARRAY_TASK_ID}), quit\"","title":"Submitting FSL Jobs"},{"location":"matlab/fieldtrip/","text":"Fieldtrip on Slurm Example contributed by Ben Griffiths. This is an example script running a fieldtrip analysis on EEG data acqurired during a visual flicker task. The data is read in, filtered, epoched, ICA'd, re-referenced, then plotted. The core function can be executed on the MatLab GUI App during an interactive session, or submitted to BlueEBAR using the bash script below. %% Basic Preprocessing % A script to demonstrate how one can (superficially) preprocessing EEG % data using Fieldtrip, Matlab and BlueBEAR. % % Benjamin J. Griffiths (b.griffiths.1 [at] bham.ac.uk) % 28th March 2023 %% Prepare Workspace % define root directory where data is stored root_dir = '/rds/projects/g/griffibz-example-project/msc-eeg-23/'; % add fieldtrip to path addpath('/rds/projects/g/griffibz-example-project/fieldtrip/') ft_defaults % define participant number subj = 1; %% Filter Raw Data % load data cfg = []; cfg.dataset = sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_eeg.eeg', root_dir, subj, subj); % dynamically determine dataset name data = ft_preprocessing(cfg); % remove external and trigger channels cfg = []; cfg.channel = {'all', '-EX*', '-Status'}; % select all channels except any external (-EX*) or trigger (-Status) channel data = ft_selectdata(cfg, data); % filter data cfg = []; %cfg.hpfilter = 'yes'; % apply high-pass filter %cfg.hpfreq = 0.8; % use high-pass to suppress frequencies < 0.8Hz cfg.lpfilter = 'yes'; % apply low-pass filter cfg.lpfreq = 120; % use low-pass to suppress frequencies > 120Hz cfg.bsfilter = 'yes'; % apply band-pass filter cfg.bsfreq = [49 51]; % use band-pass to suppress frequencies netween 49Hz and 51Hz data = ft_preprocessing(cfg, data); %% Epoch Data % load in BIDS event file events = readtable(sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_events.tsv', root_dir, subj, subj),'Filetype','text'); % dynamically determine dataset name % define Fieldtrip-style event structure trl_start = -2; % start trial 2 seconds before trigger trl_end = 4; % end trial 4 seconds after trigger trl_def(:,1) = events.sample + (trl_start * data.fsample); % define samples to start trial trl_def(:,2) = events.sample + (trl_end * data.fsample); % define samples to end trial trl_def(:,3) = trl_start * data.fsample; % define when time = 0 occurs relative to start of trial % epoch data cfg = []; cfg.trl = trl_def; data = ft_redefinetrial(cfg, data); % load in trialinfo load(sprintf('%s/bids/sourcedata/sub-%02.0f_trialinfo.mat', root_dir, subj)) data.trialinfo = trialinfo; % add trialinfo to data structure % tidy workspace clear events trl_start trl_end trl_def trialinfo %% Run ICA % restrict to retrieval trials cfg = []; cfg.trials = find(cellfun(@(x) strcmpi(x.trl_type, 'retrieval'), data.trialinfo)); data = ft_selectdata(cfg, data); % reduce sample rate cfg = []; cfg.resamplefs = 256; % drop sample rate from 1024Hz to 256Hz data = ft_resampledata(cfg, data); % run ica rng(subj) % set random seed to ensure reproducible outputs every time the function is run ica = ft_componentanalysis([], data); % \"cfg\" need not be defined if using default settings % visualise first 20 components (commented to stop execution when running via Slurm) %ft_topoplotIC(struct('component',1:20,'layout','biosemi128.lay'), ica) % remove components cfg = []; cfg.component = [1 3]; % 1 = eyeblink, 3 = saccade data = ft_rejectcomponent(cfg, ica); %% Re-reference Data % re-reference to the average of all channels cfg = []; cfg.reref = 'yes'; cfg.refchannel = 'all'; data = ft_preprocessing(cfg, data); %% Plot Results % get timelocked average of data cfg = []; cfg.channel = 'A*'; % restrict to posterior quadrant of channels tml = ft_timelockanalysis(cfg, data); % baseline correct timelocked average cfg = []; cfg.baseline = [-0.25 -0.05]; % set baseline as -250ms to -50ms tml = ft_timelockbaseline(cfg, tml); % plot ERP h = figure; subplot(2,1,1); hold on plot(tml.time, mean(tml.avg)) xlim([-0.5 2.5]) xline(0,'k--') yline(0,'k-') xlabel('Time (s)') ylabel('Amplitude (uV)') title('Visual Evoked Potential') % cycle through trials pow = cell(8, 1); % create empty cells for eight conditions for trl = 1 : numel(data.trial) condition = data.trialinfo{trl}.ret_freq; % determine flicker condition channels_A = cellfun(@(x) strncmpi(x, 'A', 1), data.label); % identify posterior channels signal = data.trial{trl}(channels_A, :); % extract signal over posterior channels pow{condition}(end+1,:) = mean(abs(fft(signal')')); % compute FFT end % determine frequencies of FFT freqs = linspace(0, data.fsample, size(pow{1},2)); % plot FFT for each condition subplot(2,1,2); hold on for condition = 1 : numel(pow) plot(freqs,mean(pow{condition})); end xlim([6, 42]) ylim([0, 700]) title('Power Spectrum') xlabel('Frequency (Hz)') ylabel('Power (arb. units)') legend({'60Hz','40Hz','30Hz','24Hz','20Hz','17.1Hz','15Hz','Baseline'}) % save figure in root directory saveas(h, sprintf('%s/basic_preproc_output.jpg', root_dir)) #!/bin/bash #SBATCH --ntasks 10 #SBATCH --nodes 1 #SBATCH --time 1:0:0 #SBATCH --qos bbdefault #SBATCH --mail-type ALL set -e module purge; module load bluebear module load MATLAB/2021b matlab -nodisplay -r \"basic_preprocessing; exit;\"","title":"Fieldtrip on Slurm"},{"location":"matlab/fieldtrip/#fieldtrip-on-slurm","text":"Example contributed by Ben Griffiths. This is an example script running a fieldtrip analysis on EEG data acqurired during a visual flicker task. The data is read in, filtered, epoched, ICA'd, re-referenced, then plotted. The core function can be executed on the MatLab GUI App during an interactive session, or submitted to BlueEBAR using the bash script below. %% Basic Preprocessing % A script to demonstrate how one can (superficially) preprocessing EEG % data using Fieldtrip, Matlab and BlueBEAR. % % Benjamin J. Griffiths (b.griffiths.1 [at] bham.ac.uk) % 28th March 2023 %% Prepare Workspace % define root directory where data is stored root_dir = '/rds/projects/g/griffibz-example-project/msc-eeg-23/'; % add fieldtrip to path addpath('/rds/projects/g/griffibz-example-project/fieldtrip/') ft_defaults % define participant number subj = 1; %% Filter Raw Data % load data cfg = []; cfg.dataset = sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_eeg.eeg', root_dir, subj, subj); % dynamically determine dataset name data = ft_preprocessing(cfg); % remove external and trigger channels cfg = []; cfg.channel = {'all', '-EX*', '-Status'}; % select all channels except any external (-EX*) or trigger (-Status) channel data = ft_selectdata(cfg, data); % filter data cfg = []; %cfg.hpfilter = 'yes'; % apply high-pass filter %cfg.hpfreq = 0.8; % use high-pass to suppress frequencies < 0.8Hz cfg.lpfilter = 'yes'; % apply low-pass filter cfg.lpfreq = 120; % use low-pass to suppress frequencies > 120Hz cfg.bsfilter = 'yes'; % apply band-pass filter cfg.bsfreq = [49 51]; % use band-pass to suppress frequencies netween 49Hz and 51Hz data = ft_preprocessing(cfg, data); %% Epoch Data % load in BIDS event file events = readtable(sprintf('%s/bids/sub-%02.0f/eeg/sub-%02.0f_task-eeg-flicker_events.tsv', root_dir, subj, subj),'Filetype','text'); % dynamically determine dataset name % define Fieldtrip-style event structure trl_start = -2; % start trial 2 seconds before trigger trl_end = 4; % end trial 4 seconds after trigger trl_def(:,1) = events.sample + (trl_start * data.fsample); % define samples to start trial trl_def(:,2) = events.sample + (trl_end * data.fsample); % define samples to end trial trl_def(:,3) = trl_start * data.fsample; % define when time = 0 occurs relative to start of trial % epoch data cfg = []; cfg.trl = trl_def; data = ft_redefinetrial(cfg, data); % load in trialinfo load(sprintf('%s/bids/sourcedata/sub-%02.0f_trialinfo.mat', root_dir, subj)) data.trialinfo = trialinfo; % add trialinfo to data structure % tidy workspace clear events trl_start trl_end trl_def trialinfo %% Run ICA % restrict to retrieval trials cfg = []; cfg.trials = find(cellfun(@(x) strcmpi(x.trl_type, 'retrieval'), data.trialinfo)); data = ft_selectdata(cfg, data); % reduce sample rate cfg = []; cfg.resamplefs = 256; % drop sample rate from 1024Hz to 256Hz data = ft_resampledata(cfg, data); % run ica rng(subj) % set random seed to ensure reproducible outputs every time the function is run ica = ft_componentanalysis([], data); % \"cfg\" need not be defined if using default settings % visualise first 20 components (commented to stop execution when running via Slurm) %ft_topoplotIC(struct('component',1:20,'layout','biosemi128.lay'), ica) % remove components cfg = []; cfg.component = [1 3]; % 1 = eyeblink, 3 = saccade data = ft_rejectcomponent(cfg, ica); %% Re-reference Data % re-reference to the average of all channels cfg = []; cfg.reref = 'yes'; cfg.refchannel = 'all'; data = ft_preprocessing(cfg, data); %% Plot Results % get timelocked average of data cfg = []; cfg.channel = 'A*'; % restrict to posterior quadrant of channels tml = ft_timelockanalysis(cfg, data); % baseline correct timelocked average cfg = []; cfg.baseline = [-0.25 -0.05]; % set baseline as -250ms to -50ms tml = ft_timelockbaseline(cfg, tml); % plot ERP h = figure; subplot(2,1,1); hold on plot(tml.time, mean(tml.avg)) xlim([-0.5 2.5]) xline(0,'k--') yline(0,'k-') xlabel('Time (s)') ylabel('Amplitude (uV)') title('Visual Evoked Potential') % cycle through trials pow = cell(8, 1); % create empty cells for eight conditions for trl = 1 : numel(data.trial) condition = data.trialinfo{trl}.ret_freq; % determine flicker condition channels_A = cellfun(@(x) strncmpi(x, 'A', 1), data.label); % identify posterior channels signal = data.trial{trl}(channels_A, :); % extract signal over posterior channels pow{condition}(end+1,:) = mean(abs(fft(signal')')); % compute FFT end % determine frequencies of FFT freqs = linspace(0, data.fsample, size(pow{1},2)); % plot FFT for each condition subplot(2,1,2); hold on for condition = 1 : numel(pow) plot(freqs,mean(pow{condition})); end xlim([6, 42]) ylim([0, 700]) title('Power Spectrum') xlabel('Frequency (Hz)') ylabel('Power (arb. units)') legend({'60Hz','40Hz','30Hz','24Hz','20Hz','17.1Hz','15Hz','Baseline'}) % save figure in root directory saveas(h, sprintf('%s/basic_preproc_output.jpg', root_dir)) #!/bin/bash #SBATCH --ntasks 10 #SBATCH --nodes 1 #SBATCH --time 1:0:0 #SBATCH --qos bbdefault #SBATCH --mail-type ALL set -e module purge; module load bluebear module load MATLAB/2021b matlab -nodisplay -r \"basic_preprocessing; exit;\"","title":"Fieldtrip on Slurm"},{"location":"matlab/matlab/","text":"MatLab Interactive MatLab sessions run as a GUI App accessible from the Bear Portal . Please follow the information on the Bear Technical Docs to start up an interactive MatLab session. Some parallelisation is available through parfor loops within single MatLab but users looking for to run many individual matlab scripts in parallel are likely to want to use the Slurm job submissions . Examples of both are included below. Neuroimaging toolboxes Neuroimaging toolboxes can be added to the MatLab path on BlueBEAR in the normal way. Toolboxes can be downloaded from the developer and stored on an RDS space. These folders can be added to the path within a MatLab session using addpath . addpath(genpath('/rds/q/quinna-example-project/code/fieldtrip')) These pages include some specific examples using popular MatLab toolboxes Fieldtrip EEGLab SPM Parallel for-loop Simple parallelisation of a for-loop can be performed using parfor . This functionality is provided by MatLab and enables faster processing of for loops simply by changing the syntax at the start to say parfor rather than for . Here is an example function which makes use of parfor whilst computing GLMs using SPM. function glm_level1(model) % This function takes a model structure as input and performs first-level % estimations in a General Linear Model (GLM) analysis for a set of subjects. subjects = model.Subj; % FIRST LEVEL (individual) estimations % Get the number of subjects to be processed. N = size(subjects,2); % Iterate over each subject in \"subjects\" using parallel processing parfor i = 1:N % Get the current subject ID from \"subjects\" id = subjects(i); % Get the corresponding BIDS (Brain Imaging Data Structure) ID and % session information for the current subject. BIDS_id = model.ids{id}; BIDS_sess = model.sess{id}; % Construct the path to the GLM folder for the current subject. path = [model.glmfolder BIDS_id]; % Construct the path to the SPM.mat file for the current subject. modelfile = [path '/SPM.mat']; % Delete the existing SPM.mat file for the current subject (clean % up previously done models) delete(modelfile); % Create a job structure for the current subject. job = analysis_job_func(BIDS_id, BIDS_sess, model); % Create an empty cell array to be used as inputs for the \"spm_jobman\" function. inputs = cell(0,1); % Set the SPM defaults to 'FMRI'. spm('defaults', 'FMRI'); % Run the current job using the \"spm_jobman\" function. spm_jobman('run', job, inputs{:}); end end Example contributed by Arkady Konovalov NOTE: Make sure you specify the appropriate number of cores when starting the MatLab GUI App, you may not notice a substantial speed-up if you run MatLab using the default of 4 cores. Do try to avoid asking for substantially more than you might need however - BlueBEAR is a shared resource. Submitting Matlab jobs with parfor to Bear Example contributed by Dagmar Fraser The following Matlab code performs some matrix calculations on simulated data. The inclusion of a parfor loop means that the code can take advantage of computers with multiple CPUs to accelerate processing. tic n = 200; A= 500; a = zeros(1,n); parfor i = 1:n a(i) = max(abs(eig(rand(A)))); end toc You can run this code in an interactive Matlab session, or save it as a script that can be executed on the big cluster. If we save this file as parforDemo.m , we can write a second 'submission' script to execute it on the cluster. #!/bin/bash #SBATCH --ntasks 8 #SBATCH --time 5:0 #SBATCH --qos bbshort #SBATCH --mail-type ALL set -e module purge module load bluebear module load MATLAB/2020a matlab -nodisplay -r parforDemo If we save that second script as RunMyCode.sh it can be run using sbatch RunMyCode.sh on a terminal to send the job to the cluster. The ntasks line specifies we are looking to use 8 cores. The last line contains the filename we are sending to MATLAB to execute Submitting multiple MatLab jobs The previous example submits a single Matlab job that uses parfor BlueBEAR, for larger analyses we may want to parallelise jobs across entire matlab instances. This can be done by submitting MatLab jobs to BEAR using Slurm. The BEAR Technical Docs contain a simple example on submitting a matlab job to bear . For neuroimaging analyses, you'll generally need to organise your scripts so that each part that you want to parallelise runs from a single function that takes a single ID as an argument. Here is a specific example that runs a function e1_fun_ICA on each of 48 datasets. #!/bin/bash #SBATCH --ntasks 1 #SBATCH --time 30:0 #SBATCH --mem 50G #SBATCH --qos bbdefault #SBATCH --array=1-48 set -eu module purge; module load bluebear # load the MATLAB version you need module load MATLAB/2019b # apply matlab script to each index in the array # (the MATLAB script is programmed such that the input ID is used as the subject ID) matlab -nodisplay -r \"run /rds/homes/d/dueckerk/startup.m, e1_fun_ICA(${SLURM_ARRAY_TASK_ID}), quit\" Example contributed by Katharina Deucker","title":"MatLab"},{"location":"matlab/matlab/#matlab","text":"Interactive MatLab sessions run as a GUI App accessible from the Bear Portal . Please follow the information on the Bear Technical Docs to start up an interactive MatLab session. Some parallelisation is available through parfor loops within single MatLab but users looking for to run many individual matlab scripts in parallel are likely to want to use the Slurm job submissions . Examples of both are included below.","title":"MatLab"},{"location":"matlab/matlab/#neuroimaging-toolboxes","text":"Neuroimaging toolboxes can be added to the MatLab path on BlueBEAR in the normal way. Toolboxes can be downloaded from the developer and stored on an RDS space. These folders can be added to the path within a MatLab session using addpath . addpath(genpath('/rds/q/quinna-example-project/code/fieldtrip')) These pages include some specific examples using popular MatLab toolboxes Fieldtrip EEGLab SPM","title":"Neuroimaging toolboxes"},{"location":"matlab/matlab/#parallel-for-loop","text":"Simple parallelisation of a for-loop can be performed using parfor . This functionality is provided by MatLab and enables faster processing of for loops simply by changing the syntax at the start to say parfor rather than for . Here is an example function which makes use of parfor whilst computing GLMs using SPM. function glm_level1(model) % This function takes a model structure as input and performs first-level % estimations in a General Linear Model (GLM) analysis for a set of subjects. subjects = model.Subj; % FIRST LEVEL (individual) estimations % Get the number of subjects to be processed. N = size(subjects,2); % Iterate over each subject in \"subjects\" using parallel processing parfor i = 1:N % Get the current subject ID from \"subjects\" id = subjects(i); % Get the corresponding BIDS (Brain Imaging Data Structure) ID and % session information for the current subject. BIDS_id = model.ids{id}; BIDS_sess = model.sess{id}; % Construct the path to the GLM folder for the current subject. path = [model.glmfolder BIDS_id]; % Construct the path to the SPM.mat file for the current subject. modelfile = [path '/SPM.mat']; % Delete the existing SPM.mat file for the current subject (clean % up previously done models) delete(modelfile); % Create a job structure for the current subject. job = analysis_job_func(BIDS_id, BIDS_sess, model); % Create an empty cell array to be used as inputs for the \"spm_jobman\" function. inputs = cell(0,1); % Set the SPM defaults to 'FMRI'. spm('defaults', 'FMRI'); % Run the current job using the \"spm_jobman\" function. spm_jobman('run', job, inputs{:}); end end Example contributed by Arkady Konovalov NOTE: Make sure you specify the appropriate number of cores when starting the MatLab GUI App, you may not notice a substantial speed-up if you run MatLab using the default of 4 cores. Do try to avoid asking for substantially more than you might need however - BlueBEAR is a shared resource.","title":"Parallel for-loop"},{"location":"matlab/matlab/#submitting-matlab-jobs-with-parfor-to-bear","text":"Example contributed by Dagmar Fraser The following Matlab code performs some matrix calculations on simulated data. The inclusion of a parfor loop means that the code can take advantage of computers with multiple CPUs to accelerate processing. tic n = 200; A= 500; a = zeros(1,n); parfor i = 1:n a(i) = max(abs(eig(rand(A)))); end toc You can run this code in an interactive Matlab session, or save it as a script that can be executed on the big cluster. If we save this file as parforDemo.m , we can write a second 'submission' script to execute it on the cluster. #!/bin/bash #SBATCH --ntasks 8 #SBATCH --time 5:0 #SBATCH --qos bbshort #SBATCH --mail-type ALL set -e module purge module load bluebear module load MATLAB/2020a matlab -nodisplay -r parforDemo If we save that second script as RunMyCode.sh it can be run using sbatch RunMyCode.sh on a terminal to send the job to the cluster. The ntasks line specifies we are looking to use 8 cores. The last line contains the filename we are sending to MATLAB to execute","title":"Submitting Matlab jobs with parfor to Bear"},{"location":"matlab/matlab/#submitting-multiple-matlab-jobs","text":"The previous example submits a single Matlab job that uses parfor BlueBEAR, for larger analyses we may want to parallelise jobs across entire matlab instances. This can be done by submitting MatLab jobs to BEAR using Slurm. The BEAR Technical Docs contain a simple example on submitting a matlab job to bear . For neuroimaging analyses, you'll generally need to organise your scripts so that each part that you want to parallelise runs from a single function that takes a single ID as an argument. Here is a specific example that runs a function e1_fun_ICA on each of 48 datasets. #!/bin/bash #SBATCH --ntasks 1 #SBATCH --time 30:0 #SBATCH --mem 50G #SBATCH --qos bbdefault #SBATCH --array=1-48 set -eu module purge; module load bluebear # load the MATLAB version you need module load MATLAB/2019b # apply matlab script to each index in the array # (the MATLAB script is programmed such that the input ID is used as the subject ID) matlab -nodisplay -r \"run /rds/homes/d/dueckerk/startup.m, e1_fun_ICA(${SLURM_ARRAY_TASK_ID}), quit\" Example contributed by Katharina Deucker","title":"Submitting multiple MatLab jobs"},{"location":"mne/mne/","text":"MNE Python MNE-Python is a Python package for analysing electrophysiology (MEG, EEG, sEEG, ECoG, NIRS, etc) data. MNE-Python Versions Bear Apps has several versions of MNE-Python as modules. JupyterLab Interactive python notebooks are available to run as a JupyterLab GUI App through the Bear Portal. The pre-installed MNE python versions can be loaded as modules in the notebook session. Only the pre-installed modules available in Bear Apps are installable in the JupyterLab GUI App. Bear GUI The following bash loads mne version 1.3.1 and its dependencies. module load bear-apps/2022a module load MNE-Python/1.3.1-foss-2022a #!/bin/bash module purge; module load bluebear module load bear-apps/2021a/live module load Python/3.9.5-GCCcore-10.3.0 module load IPython/7.25.0-GCCcore-10.3.0 export VENV_DIR=\"${HOME}/virtual-environments\" export VENV_PATH=\"${VENV_DIR}/osl-bigmeg-${BB_CPU}\" # Create master dir if necessary mkdir -p ${VENV_DIR} echo ${VENV_PATH} # Check if virtual environment exists and create it if not if [[ ! -d ${VENV_PATH} ]]; then python3 -m venv --system-site-packages ${VENV_PATH} fi # Activate virtual environment source ${VENV_PATH}/bin/activate # Any additional installations pip install mne","title":"TensorFlow"},{"location":"mne/mne/#mne-python","text":"MNE-Python is a Python package for analysing electrophysiology (MEG, EEG, sEEG, ECoG, NIRS, etc) data.","title":"MNE Python"},{"location":"mne/mne/#mne-python-versions","text":"Bear Apps has several versions of MNE-Python as modules.","title":"MNE-Python Versions"},{"location":"mne/mne/#jupyterlab","text":"Interactive python notebooks are available to run as a JupyterLab GUI App through the Bear Portal. The pre-installed MNE python versions can be loaded as modules in the notebook session. Only the pre-installed modules available in Bear Apps are installable in the JupyterLab GUI App.","title":"JupyterLab"},{"location":"mne/mne/#bear-gui","text":"The following bash loads mne version 1.3.1 and its dependencies. module load bear-apps/2022a module load MNE-Python/1.3.1-foss-2022a #!/bin/bash module purge; module load bluebear module load bear-apps/2021a/live module load Python/3.9.5-GCCcore-10.3.0 module load IPython/7.25.0-GCCcore-10.3.0 export VENV_DIR=\"${HOME}/virtual-environments\" export VENV_PATH=\"${VENV_DIR}/osl-bigmeg-${BB_CPU}\" # Create master dir if necessary mkdir -p ${VENV_DIR} echo ${VENV_PATH} # Check if virtual environment exists and create it if not if [[ ! -d ${VENV_PATH} ]]; then python3 -m venv --system-site-packages ${VENV_PATH} fi # Activate virtual environment source ${VENV_PATH}/bin/activate # Any additional installations pip install mne","title":"Bear GUI"}]}